---
title: "Overview of Dialog System Evaluation Track: Dimensionality, Language, Culture and Safety at DSTC 12"
collection: publications
permalink: /publication/2024-11-01-overview-of-dialog-system-evaluation-track
excerpt: ""
date: 2024-11-01
venue: "DSTC 12"
paperurl: ''
citation: "Mendonca, J.; Zhang, L.; Mallidi, R.; Lavie, A.; Trancoso, I.; D'Haro, L. F.; Sedoc, J. (2024). &quot;Overview of Dialog System Evaluation Track: Dimensionality, Language, Culture and Safety at DSTC 12.&quot; <i>DSTC</i>."
---

The rapid advancement of Large Language Models (LLMs) has intensified the need for robust dialogue system evaluation, yet comprehensive assessment remains challenging. Traditional metrics often prove insufficient, and safety considerations are frequently narrowly defined or culturally biased. The DSTC12 Track 1, “Dialog System Evaluation: Dimensionality, Language, Culture and Safety,” is part of the ongoing effort to address these critical gaps. The track comprised two subtasks: (1) Dialogue-level, Multi-dimensional Automatic Evaluation Metrics, and (2) Multilingual and Multicultural Safety Detection. For Task 1, focused on 10 dialogue dimensions, a Llama-3-8B baseline achieved the highest average Spearman’s correlation (0.1681), indicating substantial room for improvement. In Task 2, while participating teams significantly outperformed a Llama-Guard-3-1B baseline on the multilingual safety subset (top ROC-AUC 0.9648), the baseline proved superior on the cultural subset (0.5126 ROC-AUC), highlighting critical needs in culturally-aware safety. This paper describes the datasets and baselines provided to participants, as well as submission evaluation results for each of the two proposed subtasks.
